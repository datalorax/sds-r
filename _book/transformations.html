<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.6 Transformations | Social Data Science with R</title>
  <meta name="description" content="This is basically course notes corresponding to a series of courses in educational data science, which are generally applicable to a wide range of social data science problems, taught through R." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="3.6 Transformations | Social Data Science with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is basically course notes corresponding to a series of courses in educational data science, which are generally applicable to a wide range of social data science problems, taught through R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.6 Transformations | Social Data Science with R" />
  
  <meta name="twitter:description" content="This is basically course notes corresponding to a series of courses in educational data science, which are generally applicable to a wide range of social data science problems, taught through R." />
  

<meta name="author" content="Daniel Anderson" />
<meta name="author" content="Brendan Cullen" />
<meta name="author" content="Ouafaa Hmaddi" />


<meta name="date" content="2020-10-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="missing-data.html"/>
<link rel="next" href="nonlinearity.html"/>
<script src="assets/header-attrs-2.4/header-attrs.js"></script>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="assets/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="assets/core-js-2.5.3/shim.min.js"></script>
<script src="assets/react-16.12.0/react.min.js"></script>
<script src="assets/react-16.12.0/react-dom.min.js"></script>
<script src="assets/reactwidget-1.0.0/react-tools.js"></script>
<script src="assets/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="assets/reactable-binding-0.2.0/reactable.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/iframe-resizer/3.5.16/iframeResizer.min.js" type="text/javascript"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="welcome.html"><a href="welcome.html"><i class="fa fa-check"></i><b>2</b> Welcome</a></li>
<li class="chapter" data-level="3" data-path="feature-engineering.html"><a href="feature-engineering.html"><i class="fa fa-check"></i><b>3</b> Feature Engineering</a>
<ul>
<li class="chapter" data-level="3.1" data-path="basics-of-recipes.html"><a href="basics-of-recipes.html"><i class="fa fa-check"></i><b>3.1</b> Basics of {recipes}</a></li>
<li class="chapter" data-level="3.2" data-path="creating-a-recipe.html"><a href="creating-a-recipe.html"><i class="fa fa-check"></i><b>3.2</b> Creating a recipe</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="creating-a-recipe.html"><a href="creating-a-recipe.html#order-matters"><i class="fa fa-check"></i><b>3.2.1</b> Order matters</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="encoding-categorical-data.html"><a href="encoding-categorical-data.html"><i class="fa fa-check"></i><b>3.3</b> Encoding categorical data</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="encoding-categorical-data.html"><a href="encoding-categorical-data.html#transformations-beyond-dummy-coding"><i class="fa fa-check"></i><b>3.3.1</b> Transformations beyond dummy coding</a></li>
<li class="chapter" data-level="3.3.2" data-path="encoding-categorical-data.html"><a href="encoding-categorical-data.html#handling-new-levels"><i class="fa fa-check"></i><b>3.3.2</b> Handling new levels</a></li>
<li class="chapter" data-level="3.3.3" data-path="encoding-categorical-data.html"><a href="encoding-categorical-data.html#final-thoughts-on-encoding-categorical-data"><i class="fa fa-check"></i><b>3.3.3</b> Final thoughts on encoding categorical data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="dealing-with-low-variance-predictors.html"><a href="dealing-with-low-variance-predictors.html"><i class="fa fa-check"></i><b>3.4</b> Dealing with low variance predictors</a></li>
<li class="chapter" data-level="3.5" data-path="missing-data.html"><a href="missing-data.html"><i class="fa fa-check"></i><b>3.5</b> Missing data</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="missing-data.html"><a href="missing-data.html#missing-data-via-recipes"><i class="fa fa-check"></i><b>3.5.1</b> Missing data via {recipes}</a></li>
<li class="chapter" data-level="3.5.2" data-path="missing-data.html"><a href="missing-data.html#a-few-words-of-caution"><i class="fa fa-check"></i><b>3.5.2</b> A few words of caution</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>3.6</b> Transformations</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="transformations.html"><a href="transformations.html#box-cox-and-similar-transformations"><i class="fa fa-check"></i><b>3.6.1</b> Box-Cox and similar transformations</a></li>
<li class="chapter" data-level="3.6.2" data-path="transformations.html"><a href="transformations.html#an-applied-example"><i class="fa fa-check"></i><b>3.6.2</b> An applied example</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="nonlinearity.html"><a href="nonlinearity.html"><i class="fa fa-check"></i><b>3.7</b> Nonlinearity</a></li>
<li class="chapter" data-level="3.8" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>3.8</b> PCA</a></li>
<li class="chapter" data-level="3.9" data-path="wrapping-up.html"><a href="wrapping-up.html"><i class="fa fa-check"></i><b>3.9</b> Wrapping up</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Social Data Science with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="transformations" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Transformations</h2>
<p>In standard inferential statistics, we are often concerned with the distribution of the outcome. Linear regression, for example, assumes the outcome is at least reasonably normally distributed. If this is not the case, the standard errors (in particular) can be misrepresented. We therefore generally inspect the outcome before modeling it and, if it is not approximately normally distributed, we either transform it to make it more closely approximate a normal distribution, or we use an analysis technique that does not assume normality in the outcome.</p>
<p>In predictive modeling, transformations of the predictors or the outcome(s) (or both) can sometimes help improve model performance. For example, let’s quickly simulate some data.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="transformations.html#cb84-1"></a><span class="kw">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb84-2"><a href="transformations.html#cb84-2"></a></span>
<span id="cb84-3"><a href="transformations.html#cb84-3"></a><span class="co"># parameters</span></span>
<span id="cb84-4"><a href="transformations.html#cb84-4"></a>alpha &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb84-5"><a href="transformations.html#cb84-5"></a>b1 &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb84-6"><a href="transformations.html#cb84-6"></a></span>
<span id="cb84-7"><a href="transformations.html#cb84-7"></a><span class="co"># simulate predictor variable</span></span>
<span id="cb84-8"><a href="transformations.html#cb84-8"></a>x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">100</span></span>
<span id="cb84-9"><a href="transformations.html#cb84-9"></a>log_x &lt;-<span class="st"> </span><span class="kw">log</span>(x)</span>
<span id="cb84-10"><a href="transformations.html#cb84-10"></a></span>
<span id="cb84-11"><a href="transformations.html#cb84-11"></a><span class="co"># residual SD</span></span>
<span id="cb84-12"><a href="transformations.html#cb84-12"></a>e &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">length</span>(x), <span class="dt">sd =</span> <span class="fl">0.8</span>)</span>
<span id="cb84-13"><a href="transformations.html#cb84-13"></a></span>
<span id="cb84-14"><a href="transformations.html#cb84-14"></a>y &lt;-<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>log_x <span class="op">+</span><span class="st"> </span>e</span>
<span id="cb84-15"><a href="transformations.html#cb84-15"></a></span>
<span id="cb84-16"><a href="transformations.html#cb84-16"></a>sim &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x, y)</span></code></pre></div>
<div id="htmlwidget-203c36d97b5559aa70a8" class="reactable html-widget" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-203c36d97b5559aa70a8">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],"y":[9.23,13.23,15.7,16.01,18.2,18.98,19.8,21.29,20.01,22.53,21.39,21.52,22.25,23.4,23.66,23.62,23.4,23.93,25.7,25.14,24.76,24.7,25.51,24.56,25.71,25.7,27.41,27.47,26.78,26.1,27.89,28.01,28.06,28.22,27.5,28.48,29.09,28.22,27.53,29.08,29.2,28.44,30.17,28.29,29.31,27.33,29.12,30.26,29.09,28.84,30.24,29.11,30.07,28.56,28.91,29.76,29.39,31.39,31.12,29.84,31.01,31.37,30.92,31.08,31.81,30.56,30.69,31.86,30.14,31.39,31.29,31.76,32.27,31.73,31.77,32.25,32.69,32.09,31.06,31.78,33.36,31.75,32.65,33.13,32.85,32.27,32.5,31.68,32.79,31.79,31.87,31.82,32.14,33.56,32.46,32.77,32.5,33.36,33.72,32.86]},"columns":[{"accessor":"x","name":"x","type":"numeric"},{"accessor":"y","name":"y","type":"numeric"}],"defaultPageSize":10,"paginationType":"numbers","showPageInfo":true,"minRows":1,"theme":{"backgroundColor":"transparent","borderColor":"#C7E4F5","highlightColor":"#7EC1E7","inputStyle":{"backgroundColor":"transparent"},"selectStyle":{"backgroundColor":"transparent"},"pageButtonHoverStyle":{"backgroundColor":"#B3E5D9"},"pageButtonActiveStyle":{"backgroundColor":"#B3E5D9"}},"dataKey":"f25a0275740cf41cd485a0d3944949a4"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
<p>As you can see from the above, we have simulated the data according to <span class="math inline">\(\log x\)</span>, but in our data frame only has <span class="math inline">\(x\)</span>. This is a common situation where we don’t <em>know</em> the true functional form. But of course, if we fit a linear regression model to these data, we’ll end up with high bias, particularly in the lower tail (and issues with heteroscedasticity).</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="transformations.html#cb85-1"></a><span class="kw">ggplot</span>(sim, <span class="kw">aes</span>(x, y)) <span class="op">+</span></span>
<span id="cb85-2"><a href="transformations.html#cb85-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb85-3"><a href="transformations.html#cb85-3"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>,</span>
<span id="cb85-4"><a href="transformations.html#cb85-4"></a>              <span class="dt">se =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<p>But all we have to do, in this case, is use a log transformation to the <span class="math inline">\(x\)</span> variable and our linear model fits great.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="transformations.html#cb86-1"></a>sim <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb86-2"><a href="transformations.html#cb86-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_x =</span> <span class="kw">log</span>(x)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb86-3"><a href="transformations.html#cb86-3"></a><span class="st">  </span><span class="kw">head</span>()</span></code></pre></div>
<pre><code>##   x         y     log_x
## 1 1  9.230453 0.0000000
## 2 2 13.231715 0.6931472
## 3 3 15.700092 1.0986123
## 4 4 16.009766 1.3862944
## 5 5 18.203816 1.6094379
## 6 6 18.982897 1.7917595</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="transformations.html#cb88-1"></a>sim <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb88-2"><a href="transformations.html#cb88-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_x =</span> <span class="kw">log</span>(x)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb88-3"><a href="transformations.html#cb88-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(log_x, y)) <span class="op">+</span></span>
<span id="cb88-4"><a href="transformations.html#cb88-4"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb88-5"><a href="transformations.html#cb88-5"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>,</span>
<span id="cb88-6"><a href="transformations.html#cb88-6"></a>              <span class="dt">se =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>Note that the model is linear in the transformed units, but curvilinear on the raw scale.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="transformations.html#cb89-1"></a>sim <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb89-2"><a href="transformations.html#cb89-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_x =</span> <span class="kw">log</span>(x)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb89-3"><a href="transformations.html#cb89-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x, y)) <span class="op">+</span></span>
<span id="cb89-4"><a href="transformations.html#cb89-4"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb89-5"><a href="transformations.html#cb89-5"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>,</span>
<span id="cb89-6"><a href="transformations.html#cb89-6"></a>              <span class="dt">se =</span> <span class="ot">FALSE</span>,</span>
<span id="cb89-7"><a href="transformations.html#cb89-7"></a>              <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(x))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>So in this case, a log transformation to the x variable works perfect (as we would expect, given that we simulated the data to be this way). But how do we know <em>how</em> to transform variables?</p>
<div id="box-cox-and-similar-transformations" class="section level3" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> Box-Cox and similar transformations</h3>
<p>A more general formula for transforming variables is given by the <a href="https://en.wikipedia.org/wiki/Power_transform#Box–Cox_transformation">Box-Cox transformation</a>, defined by</p>
<p><span class="math display">\[
\begin{equation}
 x^* =
    \begin{cases}
      \frac{x^\lambda-1}{\lambda}, &amp; \text{if}\ \lambda \neq 0 \\
       \log\left(x\right), &amp; \text{if}\ \lambda = 0
    \end{cases}
\end{equation}
\]</span>
where <span class="math inline">\(x\)</span> represents the variable in its raw units, and <span class="math inline">\(x^*\)</span> represents the transformed variable. The Box-Cox transformation is a <em>power</em> transformation, where the intent is to estimate <span class="math inline">\(\lambda\)</span>. Note that if <span class="math inline">\(\lambda\)</span> is estimated as zero, the power transformation is the same as a log transformation, otherwise the top portion of the equation is used. Helpfully, specific values of <span class="math inline">\(\lambda\)</span> map to common transformations.</p>
<ul>
<li><span class="math inline">\(\lambda = 1\)</span>: No transformation</li>
<li><span class="math inline">\(\lambda = 0.5\)</span>: square root transformation</li>
<li><span class="math inline">\(\lambda = 0\)</span>: log transformation</li>
<li><span class="math inline">\(\lambda = -1\)</span>: inverse</li>
</ul>
<p>Given the above, we would expect that <span class="math inline">\(\lambda\)</span> would be estimated close to zero with our simulated data. Let’s try using {recipes}. To access the actual <span class="math inline">\(\lambda\)</span> value, we’ll need to take a brief foray into tidying recipes.</p>
<div id="tidying-recipes" class="section level4" number="3.6.1.1">
<h4><span class="header-section-number">3.6.1.1</span> Tidying recipes</h4>
<p>Let’s first specify the recipe with a Box-Cox transformation to our x variable</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="transformations.html#cb90-1"></a>rec &lt;-<span class="st"> </span><span class="kw">recipe</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> sim) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb90-2"><a href="transformations.html#cb90-2"></a><span class="st">  </span><span class="kw">step_BoxCox</span>(<span class="kw">all_predictors</span>())</span></code></pre></div>
<p>Now we can tidy the recipe</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="transformations.html#cb91-1"></a><span class="kw">tidy</span>(rec)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 6
##   number operation type   trained skip  id          
##    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;       
## 1      1 step      BoxCox FALSE   FALSE BoxCox_dj7Ww</code></pre>
<p>In this case, our recipe is incredibly simple. We have one step, which is a Box-Cox transformation. Let’s make the recipe a bit more complicated just for completeness.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="transformations.html#cb93-1"></a>rec &lt;-<span class="st"> </span><span class="kw">recipe</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> sim) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb93-2"><a href="transformations.html#cb93-2"></a><span class="st">  </span><span class="kw">step_impute_linear</span>(<span class="kw">all_predictors</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb93-3"><a href="transformations.html#cb93-3"></a><span class="st">  </span><span class="kw">step_nzv</span>(<span class="kw">all_predictors</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb93-4"><a href="transformations.html#cb93-4"></a><span class="st">  </span><span class="kw">step_BoxCox</span>(<span class="kw">all_numeric</span>(), <span class="op">-</span><span class="kw">all_outcomes</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb93-5"><a href="transformations.html#cb93-5"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>(), <span class="op">-</span><span class="kw">all_outcomes</span>())</span></code></pre></div>
<p>Most of these steps won’t do anything in this case, but let’s look at the tidied recipe now.</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="transformations.html#cb94-1"></a><span class="kw">tidy</span>(rec)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 6
##   number operation type          trained skip  id                 
##    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;         &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;              
## 1      1 step      impute_linear FALSE   FALSE impute_linear_J8I0L
## 2      2 step      nzv           FALSE   FALSE nzv_8d2bJ          
## 3      3 step      BoxCox        FALSE   FALSE BoxCox_NxJt6       
## 4      4 step      dummy         FALSE   FALSE dummy_z6myS</code></pre>
<p>Now we have four steps. We can look at any one step by declaring the step number. Let’s look at the linear imputation</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="transformations.html#cb96-1"></a><span class="kw">tidy</span>(rec, <span class="dt">n =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   terms            model id                 
##   &lt;chr&gt;            &lt;lgl&gt; &lt;chr&gt;              
## 1 all_predictors() NA    impute_linear_J8I0L</code></pre>
<p>Notice there’s nothing there, because at this point the recipe is still just a blueprint. We have to <code>prep</code> the recipe if we want it to actually do any work. Let’s prep the recipe and try again.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="transformations.html#cb98-1"></a>lm_imputation &lt;-<span class="st"> </span>rec <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb98-2"><a href="transformations.html#cb98-2"></a><span class="st">  </span><span class="kw">prep</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb98-3"><a href="transformations.html#cb98-3"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">n =</span> <span class="dv">1</span>)</span>
<span id="cb98-4"><a href="transformations.html#cb98-4"></a></span>
<span id="cb98-5"><a href="transformations.html#cb98-5"></a>lm_imputation</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   terms model        id                 
##   &lt;chr&gt; &lt;named list&gt; &lt;chr&gt;              
## 1 x     &lt;lm&gt;         impute_linear_J8I0L</code></pre>
<p>And now we can see a linear model has been fit. We can even access the model itself.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="transformations.html#cb100-1"></a>lm_imputation<span class="op">$</span>model</span></code></pre></div>
<pre><code>## $x
## 
## Call:
## NULL
## 
## Coefficients:
## (Intercept)  
##        50.5</code></pre>
<p>What we get is actually a list of models, one for each predictor. But in this case there’s only one predictor, so the list is only of length 1.</p>
</div>
<div id="estimating-lambda" class="section level4" number="3.6.1.2">
<h4><span class="header-section-number">3.6.1.2</span> Estimating <span class="math inline">\(\lambda\)</span></h4>
<p>We can do the same thing to find <span class="math inline">\(\lambda\)</span> by tidying the Box-Cox step</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="transformations.html#cb102-1"></a>rec <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb102-2"><a href="transformations.html#cb102-2"></a><span class="st">  </span><span class="kw">prep</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb102-3"><a href="transformations.html#cb102-3"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">n =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   terms     value id          
##   &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;       
## 1 x     0.7170158 BoxCox_NxJt6</code></pre>
<p>And without any further work we can see that we estimated <span class="math inline">\(\lambda = 0.72\)</span>, which is pretty much directly between a square-root transformation and no transformation. Why did it not estimate a <span class="math inline">\(log\)</span> transformation as most appropriate? Because the log transformation is only ideal when view <em>relative</em> to <span class="math inline">\(y\)</span>. Put differently, the Box-Cox transformation is an <em>unsupervised</em> approach that attempts to make each variable approximate a univariate normal distribution. As we’ll see in the next section, there are other methods that can be used to help with issues of non-linearity.</p>
<p>For completeness, let’s see if the transformation helped us. We’ll use <span class="math inline">\(\lambda = 0.72\)</span> to manually transform <span class="math inline">\(x\)</span>, then plot the result.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="transformations.html#cb104-1"></a><span class="co"># transform x</span></span>
<span id="cb104-2"><a href="transformations.html#cb104-2"></a>sim &lt;-<span class="st"> </span>sim <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb104-3"><a href="transformations.html#cb104-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x_bc =</span> ((x<span class="op">^</span><span class="fl">0.72</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="fl">0.72</span>)</span>
<span id="cb104-4"><a href="transformations.html#cb104-4"></a></span>
<span id="cb104-5"><a href="transformations.html#cb104-5"></a><span class="co"># fit the model using the transformed data</span></span>
<span id="cb104-6"><a href="transformations.html#cb104-6"></a>m &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x_bc, sim)</span>
<span id="cb104-7"><a href="transformations.html#cb104-7"></a></span>
<span id="cb104-8"><a href="transformations.html#cb104-8"></a><span class="co"># add the model predictions to the data frame</span></span>
<span id="cb104-9"><a href="transformations.html#cb104-9"></a>sim &lt;-<span class="st"> </span>sim <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb104-10"><a href="transformations.html#cb104-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred =</span> <span class="kw">predict</span>(m))</span>
<span id="cb104-11"><a href="transformations.html#cb104-11"></a></span>
<span id="cb104-12"><a href="transformations.html#cb104-12"></a><span class="co"># plot the model fit using raw data on the x-axis</span></span>
<span id="cb104-13"><a href="transformations.html#cb104-13"></a><span class="kw">ggplot</span>(sim, <span class="kw">aes</span>(x, y)) <span class="op">+</span></span>
<span id="cb104-14"><a href="transformations.html#cb104-14"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb104-15"><a href="transformations.html#cb104-15"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> pred))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<p>As we can see, it’s better than the raw data, but still insufficient.</p>
</div>
</div>
<div id="an-applied-example" class="section level3" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> An applied example</h3>
<p>Let’s look at an applied example. We’ll use the <code>violence</code> data (see the full data dictionary <a href="http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized#">here</a>), and see if we can predict the neighborhoods where the number of murders are greater than zero, using the percentage of people living in poverty and the percentage of people living in dense housing units (more than one person per room) as predictors. Let’s start with a basic plot.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="transformations.html#cb105-1"></a>violence &lt;-<span class="st"> </span><span class="kw">read_csv</span>(here<span class="op">::</span><span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;violence.csv&quot;</span>))</span>
<span id="cb105-2"><a href="transformations.html#cb105-2"></a></span>
<span id="cb105-3"><a href="transformations.html#cb105-3"></a>violence &lt;-<span class="st"> </span>violence <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb105-4"><a href="transformations.html#cb105-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">murder =</span> <span class="kw">ifelse</span>(murders <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, <span class="st">&quot;Yes&quot;</span>, <span class="st">&quot;No&quot;</span>))</span>
<span id="cb105-5"><a href="transformations.html#cb105-5"></a></span>
<span id="cb105-6"><a href="transformations.html#cb105-6"></a><span class="kw">ggplot</span>(violence, <span class="kw">aes</span>(pctPoverty, houseVacant)) <span class="op">+</span></span>
<span id="cb105-7"><a href="transformations.html#cb105-7"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> murder),</span>
<span id="cb105-8"><a href="transformations.html#cb105-8"></a>             <span class="dt">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb105-9"><a href="transformations.html#cb105-9"></a>             <span class="dt">stroke =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<p>As you can see, it’s pretty difficult to see much separation here. Let’s look at the univariate views of each predictor.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="transformations.html#cb106-1"></a><span class="kw">ggplot</span>(violence, <span class="kw">aes</span>(pctPoverty)) <span class="op">+</span></span>
<span id="cb106-2"><a href="transformations.html#cb106-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="transformations.html#cb107-1"></a><span class="kw">ggplot</span>(violence, <span class="kw">aes</span>(pctPopDenseHous)) <span class="op">+</span></span>
<span id="cb107-2"><a href="transformations.html#cb107-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-63-2.png" width="672" /></p>
<p>Both predictors are quite skewed. What do they look like after transformation?</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="transformations.html#cb108-1"></a>murder_rec &lt;-<span class="st"> </span><span class="kw">recipe</span>(murder <span class="op">~</span><span class="st"> </span>., violence) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb108-2"><a href="transformations.html#cb108-2"></a><span class="st">  </span><span class="kw">step_BoxCox</span>(<span class="kw">all_numeric</span>(), <span class="op">-</span><span class="kw">all_outcomes</span>()) </span>
<span id="cb108-3"><a href="transformations.html#cb108-3"></a></span>
<span id="cb108-4"><a href="transformations.html#cb108-4"></a>transformed_murder &lt;-<span class="st"> </span>murder_rec <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb108-5"><a href="transformations.html#cb108-5"></a><span class="st">  </span><span class="kw">prep</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb108-6"><a href="transformations.html#cb108-6"></a><span class="st">  </span><span class="kw">bake</span>(<span class="dt">new_data =</span> <span class="ot">NULL</span>) </span>
<span id="cb108-7"><a href="transformations.html#cb108-7"></a></span>
<span id="cb108-8"><a href="transformations.html#cb108-8"></a><span class="kw">ggplot</span>(transformed_murder, <span class="kw">aes</span>(pctPoverty)) <span class="op">+</span></span>
<span id="cb108-9"><a href="transformations.html#cb108-9"></a><span class="st">  </span><span class="kw">geom_histogram</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="transformations.html#cb109-1"></a><span class="kw">ggplot</span>(transformed_murder, <span class="kw">aes</span>(pctPopDenseHous)) <span class="op">+</span></span>
<span id="cb109-2"><a href="transformations.html#cb109-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-64-2.png" width="672" /></p>
<p>Each of these look considerably better. What about the bivariate view?</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="transformations.html#cb110-1"></a><span class="kw">ggplot</span>(transformed_murder, <span class="kw">aes</span>(pctPoverty, pctPopDenseHous)) <span class="op">+</span></span>
<span id="cb110-2"><a href="transformations.html#cb110-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> murder),</span>
<span id="cb110-3"><a href="transformations.html#cb110-3"></a>             <span class="dt">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb110-4"><a href="transformations.html#cb110-4"></a>             <span class="dt">stroke =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>We can much more clearly see the separation here. We could almost draw a diagonal line in the data separating the classes, as below</p>
<p><img src="_main_files/figure-html/unnamed-chunk-66-1.png" width="672" /></p>
<p>There’s of course still some misclassification going on here, and that line was drawn by just eye-balling it, but even by hand we can do this much easier after the transformation.</p>
<p>What were the lambda values estimated at for these variables? Let’s check.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="transformations.html#cb111-1"></a>murder_rec <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb111-2"><a href="transformations.html#cb111-2"></a><span class="st">  </span><span class="kw">prep</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb111-3"><a href="transformations.html#cb111-3"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb111-4"><a href="transformations.html#cb111-4"></a><span class="st">  </span><span class="kw">filter</span>(terms <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;pctPoverty&quot;</span>, <span class="st">&quot;pctPopDenseHous&quot;</span>))</span></code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   terms                 value id          
##   &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt;       
## 1 pctPoverty       0.1773078  BoxCox_bG8nP
## 2 pctPopDenseHous -0.08555192 BoxCox_bG8nP</code></pre>
<p>Both are fairly close to zero, implying they are similar to log transformations.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="missing-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonlinearity.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
